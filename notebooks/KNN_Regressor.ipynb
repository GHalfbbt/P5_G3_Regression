{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regressor (KNN)\n",
    "\n",
    "En este notebook entrenamos y evaluamos un **modelo de regresi√≥n basado en vecinos cercanos (KNN-Regressor)**.  \n",
    "Este algoritmo predice el valor de una observaci√≥n en funci√≥n de la media de los valores de sus **k vecinos m√°s cercanos**.\n",
    "\n",
    "üîπ Caracter√≠sticas principales:\n",
    "- Es un modelo **basado en distancias**, no asume relaciones lineales entre variables.\n",
    "- Requiere que los datos est√©n **escalados**, porque las magnitudes afectan directamente al c√°lculo de distancias.\n",
    "- El hiperpar√°metro clave es **k** (n√∫mero de vecinos), que controla el sesgo y la varianza del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **Paso 1. Importar librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1. Importar librer√≠as\n",
    "# ===================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## **Paso 2. Cargar datasets procesados (escalados) y divis√≥n para entrenamiento**\n",
    "\n",
    "Usamos el dataset escalado porque KNN calcula distancias entre observaciones y ser√≠a injusto que variables con magnitudes grandes dominaran el c√°lculo.\n",
    "\n",
    "Si una variable tuviera valores mucho m√°s grandes que las dem√°s (ej. PIB vs. mortalidad), dominar√≠a la distancia, sesgando el modelo.\n",
    "\n",
    "Por eso cargamos el dataset **escalado** (`features_scaled.csv`), generado en el notebook `EDA_processed.ipynb` con `StandardScaler`.  \n",
    "\n",
    "Esto asegura que todas las variables tengan media 0 y varianza 1, evitando que variables con unidades m√°s grandes (por ejemplo PIB o gasto sanitario) dominen a otras m√°s peque√±as.\n",
    "\n",
    "\n",
    "**Divisi√≥n en entrenamiento y validaci√≥n**\n",
    "\n",
    "En este bloque:\n",
    "\n",
    "- Separamos el dataset en **conjunto de entrenamiento (80%)** y **conjunto de validaci√≥n (20%)**.  \n",
    "Esto nos permite entrenar el modelo con una parte de los datos y luego evaluar su rendimiento en datos que no ha visto antes.\n",
    "\n",
    "\n",
    "De esta manera, podremos comparar los algoritmos de forma justa y evitar errores de entrenamiento.\n",
    "\n",
    "- x = todas las columnas salvo la variable objetivo.\n",
    "- y = la variable objetivo.\n",
    "- train_test_split divide los datos en:\n",
    "  - x_train, y_train (80%) ‚Üí para entrenar el modelo.\n",
    "  - x_valid, y_valid (20%) ‚Üí para validar el modelo. \n",
    "  - random_state=42 ‚Üí asegura que la divisi√≥n sea reproducible.\n",
    "\n",
    "Este paso es obligatorio para poder comparar modelos en condiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 2. Cargar datasets escalados\n",
    "# ===================================\n",
    "X = pd.read_csv(\"../data/processed/features_scaled.csv\")\n",
    "y = pd.read_csv(\"../data/processed/target_y.csv\").squeeze()\n",
    "\n",
    "# ===================================\n",
    "# Divisi√≥n en train/valid\n",
    "# ===================================\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tama√±o entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Tama√±o validaci√≥n:\", X_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **Paso 3. Entrenar y evaluar modelo (baseline con k=5)**\n",
    "\n",
    "Entrenamos un modelo **KNN con k=5 vecinos** (valor por defecto habitual).  \n",
    "Calculamos las m√©tricas principales para evaluar su rendimiento:\n",
    "\n",
    "- **RMSE**: ra√≠z del error cuadr√°tico medio.  \n",
    "- **MAE**: error absoluto medio.  \n",
    "- **R¬≤**: porcentaje de varianza explicada por el modelo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 3. Entrenar y evaluar modelo baseline\n",
    "# ===================================\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "preds = knn.predict(X_valid)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "mae = mean_absolute_error(y_valid, preds)\n",
    "r2 = r2_score(y_valid, preds)\n",
    "\n",
    "print(\"üìä KNN Regressor (k=5)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## **Paso 4. Curva de validaci√≥n para distintos valores de k**\n",
    "\n",
    "Probamos diferentes valores de **k** (de 1 a 20) y evaluamos el error en validaci√≥n.\n",
    "\n",
    "Interpretaci√≥n del gr√°fico:\n",
    "- **k peque√±o (1‚Äì3)**: el modelo es muy flexible pero se sobreajusta al ruido ‚Üí error bajo en entrenamiento pero alto en validaci√≥n.  \n",
    "- **k grande (>15)**: el modelo es m√°s estable pero pierde precisi√≥n ‚Üí se vuelve demasiado \"suavizado\".  \n",
    "- El mejor k se encuentra en el punto donde el **error de validaci√≥n es m√≠nimo**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 4. Curva de validaci√≥n para distintos k\n",
    "# ===================================\n",
    "errors = []\n",
    "neighbors = range(1, 21)\n",
    "\n",
    "for k in neighbors:\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    rmse_k = np.sqrt(mean_squared_error(y_valid, preds_valid))\n",
    "    errors.append(rmse_k)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(neighbors, errors, marker=\"o\")\n",
    "plt.xlabel(\"N√∫mero de vecinos (k)\")\n",
    "plt.ylabel(\"RMSE en validaci√≥n\")\n",
    "plt.title(\"Curva de validaci√≥n KNN\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## **Paso 5. Entrenamiento final y evaluaci√≥n de KNN para calcular m√©tricas\n",
    "\n",
    "\n",
    "**Entrenamiento con el mekor **k**\n",
    "\n",
    "Despu√©s de explorar con el KNN Regressor c√≥mo var√≠a el error en funci√≥n de k (n√∫mero de vecinos), necesitamos entrenar el modelo con el mejor k, para predecir y calcular m√©tricas (RMSE, MAE y R¬≤).\n",
    "\n",
    "- Seleccionamos el mejor valor de `k` a partir de la curva de validaci√≥n (m√≠nimo error en validaci√≥n).  \n",
    "- Entrenamos un modelo KNN con ese valor √≥ptimo y evaluamos sus predicciones sobre el conjunto de validaci√≥n.\n",
    "\n",
    "üìä Las m√©tricas que obtenemos son:\n",
    "- **RMSE**: error cuadr√°tico medio (ra√≠z), penaliza m√°s los errores grandes.  \n",
    "- **MAE**: error absoluto medio, m√°s robusto ante outliers.  \n",
    "- **R¬≤**: proporci√≥n de la variabilidad explicada por el modelo (idealmente cercano a 1).\n",
    "\n",
    "üìñ Interpretaci√≥n de las m√©tricas\n",
    "\n",
    "Cuando entrenamos el KNN Regressor con el mejor k, obtenemos 3 m√©tricas clave:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**:\n",
    "      - Es la ra√≠z del error cuadr√°tico medio. Penaliza mucho los errores grandes.\n",
    "      - Un RMSE bajo indica que las predicciones est√°n cercanas a los valores reales.\n",
    "    Si el RMSE es significativamente menor que el rango t√≠pico de la variable objetivo (vida media en a√±os), es se√±al de buen ajuste.\n",
    "\n",
    "- **MAE (Mean Absolute Error)**:\n",
    "      - Es la media del error absoluto. M√°s robusto frente a outliers que el RMSE.\n",
    "      - Indica cu√°ntos \"a√±os\" (de esperanza de vida) se equivoca, de media, el modelo.\n",
    "    Si, por ejemplo, da 2.1, significa que el modelo suele errar en ¬±2 a√±os, lo cual puede ser bastante aceptable.\n",
    "\n",
    "- **R¬≤ (Coeficiente de determinaci√≥n)**:\n",
    "      - Mide la proporci√≥n de la varianza explicada por el modelo.\n",
    "      - Valores cercanos a 1 implican que el modelo explica bien los datos.\n",
    "    Un valor en torno a 0.9 o m√°s ser√≠a muy bueno; valores bajos (<0.5) indicar√≠an que el modelo no capta bien las relaciones.\n",
    "\n",
    "üëâ En resumen: si KNN devuelve m√©tricas similares o mejores que regresi√≥n lineal y comparables a Random Forest/XGBoost, puede ser un candidato fuerte. Pero si empeora, ser√° menos competitivo.\n",
    "\n",
    "Esto nos permitir√° comparar KNN con el resto de modelos en el notebook de comparativa final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 5. Entrenamiento final y evaluaci√≥n de KNN\n",
    "# ===================================\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Escogemos el mejor k (m√≠nimo error en validaci√≥n)\n",
    "best_k = errors.index(min(errors)) + 1\n",
    "print(f\"‚úÖ Mejor n√∫mero de vecinos (k): {best_k}\")\n",
    "\n",
    "# Entrenar modelo con ese k\n",
    "knn_final = KNeighborsRegressor(n_neighbors=best_k)\n",
    "knn_final.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "preds_knn = knn_final.predict(X_valid)\n",
    "\n",
    "# M√©tricas\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds_knn))\n",
    "mae = mean_absolute_error(y_valid, preds_knn)\n",
    "r2 = r2_score(y_valid, preds_knn)\n",
    "\n",
    "print(\"\\nüìä KNN Regressor (modelo final)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## **Paso 6. Gr√°fico de predicciones vs valores reales (KNN Regressor)**\n",
    "\n",
    "Este gr√°fico es clave:\n",
    "\n",
    "- Si los puntos se concentran **cerca de la l√≠nea roja discontinua (y = x)**, significa que las predicciones del modelo son bastante precisas y se acercan bien a los valores reales.  \n",
    "- La **dispersi√≥n alrededor de la l√≠nea** indica errores en las predicciones: cuanto m√°s lejos est√° un punto de la recta, mayor es la diferencia entre lo predicho y lo real.  \n",
    "- Si aparece un **patr√≥n sistem√°tico** (por ejemplo, subestimar en valores altos o sobreestimar en valores bajos), refleja una limitaci√≥n del modelo para generalizar en esas regiones.  \n",
    "- Una **dispersi√≥n amplia y sin patr√≥n claro** puede indicar que el modelo no est√° captando bien la complejidad de los datos y que ser√≠a necesario ajustar el hiperpar√°metro `k` (n√∫mero de vecinos).  \n",
    "\n",
    "üëâ **En resumen**:  \n",
    "- Una nube de puntos bien alineada con la recta implica **buen ajuste**.  \n",
    "- Una dispersi√≥n notable sugiere **errores relevantes**.  \n",
    "- Patrones de sub/sobreestimaci√≥n muestran que el KNN podr√≠a necesitar **ajuste de par√°metros** o que no es el algoritmo m√°s adecuado para el dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 6. Visualizaci√≥n: predicciones vs valores reales\n",
    "# ===================================\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, preds_knn, alpha=0.5)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], \"r--\")\n",
    "plt.xlabel(\"Valores reales (y_valid)\")\n",
    "plt.ylabel(\"Predicciones (KNN)\")\n",
    "plt.title(\"Predicciones vs Reales - KNN Regressor\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## **Paso 7. Optimizaci√≥n del hiperpar√°metro k en KNN Regressor con GridSearchCV\n",
    "\n",
    "El par√°metro m√°s importante en **KNN Regressor** es `n_neighbors` (el n√∫mero de vecinos considerados para predecir un valor).  \n",
    "- Un `k` muy bajo (pocos vecinos) hace que el modelo sea muy sensible al ruido ‚Üí **sobreajuste (overfitting)**.  \n",
    "- Un `k` muy alto (muchos vecinos) suaviza demasiado las predicciones ‚Üí **subajuste (underfitting)**.  \n",
    "\n",
    "Usaremos **GridSearchCV** para probar distintos valores de `k` y encontrar el que minimiza el error.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 7. GridSearchCV para optimizar KNN\n",
    "# ===================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Definimos la rejilla de b√∫squeda\n",
    "param_grid = {\"n_neighbors\": list(range(2, 31))}  # probamos k de 2 a 30\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(\n",
    "    knn, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring=\"neg_root_mean_squared_error\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"üìä Mejor par√°metro k encontrado:\", grid_search.best_params_)\n",
    "print(f\"Mejor RMSE validaci√≥n: {-grid_search.best_score_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## üìå Interpretaci√≥n de los resultados de GridSearchCV en KNN\n",
    "\n",
    "El mejor valor encontrado para el par√°metro `k` fue:\n",
    "\n",
    "- **k = 3**\n",
    "- **RMSE validaci√≥n ‚âà 2.958**\n",
    "\n",
    "### üîé Lectura:\n",
    "- Un valor tan bajo de `k` significa que el modelo est√° utilizando √∫nicamente **3 vecinos m√°s cercanos** para hacer cada predicci√≥n.  \n",
    "- Esto indica que los datos **tienen suficiente estructura local** como para que pocos vecinos sean representativos.  \n",
    "- Sin embargo, tambi√©n es un indicio de que el modelo puede ser **sensible al ruido** (overfitting), ya que predice fuertemente influenciado por los vecinos m√°s cercanos.  \n",
    "\n",
    "### ‚úÖ Conclusi√≥n:\n",
    "- El rendimiento (RMSE ‚âà 2.96) es **aceptable**, aunque no tan bueno como los modelos m√°s potentes como **Random Forest o XGBoost**, que capturan relaciones m√°s complejas.  \n",
    "- Este resultado nos confirma que **KNN puede servir como baseline no lineal**, pero no es el modelo m√°s robusto para este dataset.  \n",
    "\n",
    "üëâ Lo interesante ser√° ver en el **notebook comparativo** c√≥mo se posiciona KNN frente al resto de algoritmos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## üìä Curva de validaci√≥n: RMSE vs. n√∫mero de vecinos (k)\n",
    "\n",
    "Este gr√°fico nos muestra c√≥mo cambia el error (RMSE) en validaci√≥n al variar el n√∫mero de vecinos `k`.  \n",
    "\n",
    "- Una curva en **forma de U** es habitual. Muestra c√≥mo evoluciona el error (RMSE) en validaci√≥n seg√∫n el n√∫mero de vecinos (`k`) del modelo **KNN Regressor**: \n",
    "  - Con **k muy bajo** (ej. 1-3), el modelo tiende a **sobreajustar** (overfitting).  \n",
    "  - Con **k muy alto** (ej. 50+), el modelo tiende a **subajustar** (underfitting), ya que promedia demasiados vecinos.  \n",
    "  - La **l√≠nea roja discontinua en k=3** marca el punto donde el RMSE es m√≠nimo, indica el **k √≥ptimo** seg√∫n validaci√≥n.\n",
    "  - Este valor indica que, para nuestro dataset, el modelo alcanza su mejor rendimiento considerando **3 vecinos m√°s cercanos**.  \n",
    "  - A la izquierda de k=3, el modelo tiene tendencia a **sobreajustar**: se adapta demasiado al ruido de los datos y el error aumenta.  \n",
    "  - A la derecha de k=3, el error empieza a crecer porque el modelo **subajusta**: al promediar demasiados vecinos, pierde la capacidad de capturar patrones locales.  \n",
    "\n",
    "En conclusi√≥n, **k=3 ofrece el equilibrio √≥ptimo entre sesgo y varianza** en este dataset, seg√∫n la m√©trica RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 8. Curva de validaci√≥n RMSE vs k\n",
    "# ===================================\n",
    "k_values = range(1, 31)\n",
    "rmse_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_valid)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_values, rmse_scores, marker=\"o\")\n",
    "plt.axvline(3, color=\"red\", linestyle=\"--\", label=\"Mejor k=3\")\n",
    "plt.title(\"Curva de validaci√≥n: RMSE vs k\")\n",
    "plt.xlabel(\"N√∫mero de vecinos (k)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## **Paso 9. Comparaci√≥n de m√©tricas seg√∫n el n√∫mero de vecinos (k)**\n",
    "\n",
    "Hasta ahora hemos evaluado solo el **RMSE** en la curva de validaci√≥n.  \n",
    "Sin embargo, es √∫til observar tambi√©n c√≥mo evolucionan otras m√©tricas como el **MAE** y el **R¬≤** al variar `k`.\n",
    "\n",
    "Esto nos permite:\n",
    "- Confirmar si el valor √≥ptimo de `k` es consistente en todas las m√©tricas.  \n",
    "- Entender mejor el comportamiento del modelo:  \n",
    "  - **RMSE** penaliza m√°s los errores grandes.  \n",
    "  - **MAE** mide el error medio absoluto, m√°s robusto a outliers.  \n",
    "  - **R¬≤** indica la proporci√≥n de varianza explicada por el modelo.  \n",
    "\n",
    "El siguiente gr√°fico muestra la evoluci√≥n de estas tres m√©tricas a medida que aumentamos `k`.\n",
    "\n",
    "Este gr√°fico nos dar√° una visi√≥n conjunta:\n",
    "- Confirmar√° que k=3 es √≥ptimo no solo en RMSE, sino tambi√©n si se mantiene bajo en MAE y razonable en R¬≤.\n",
    "- Si alguna m√©trica se comporta diferente, se deber√° a una limitaci√≥n del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Comparaci√≥n de m√©tricas con distintos k\n",
    "# ===================================\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "k_values = range(1, 21)\n",
    "rmse_list, mae_list, r2_list = [], [], []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_valid)\n",
    "    \n",
    "    rmse_list.append(np.sqrt(mean_squared_error(y_valid, preds)))\n",
    "    mae_list.append(mean_absolute_error(y_valid, preds))\n",
    "    r2_list.append(r2_score(y_valid, preds))\n",
    "\n",
    "# Graficar resultados\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_values, rmse_list, marker=\"o\", label=\"RMSE\")\n",
    "plt.plot(k_values, mae_list, marker=\"s\", label=\"MAE\")\n",
    "plt.plot(k_values, r2_list, marker=\"^\", label=\"R¬≤\")\n",
    "plt.axvline(best_k, color=\"red\", linestyle=\"--\", label=f\"Mejor k={best_k}\")\n",
    "\n",
    "plt.title(\"Evoluci√≥n de m√©tricas seg√∫n k en KNN Regressor\")\n",
    "plt.xlabel(\"N√∫mero de vecinos (k)\")\n",
    "plt.ylabel(\"Valor de la m√©trica\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Salvar m√©tricas en CSV\n",
    "# ===================================\n",
    "\n",
    "# ===================================\n",
    "# Funci√≥n para guardar m√©tricas estandarizadas\n",
    "# ===================================\n",
    "def save_results(model_name, y_true, y_pred, filepath):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas (RMSE, MAE, R¬≤) y guarda en CSV estandarizado.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = pd.DataFrame([{\n",
    "        \"Modelo\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R¬≤\": r2\n",
    "    }])\n",
    "\n",
    "    results.to_csv(filepath, index=False)\n",
    "    print(f\"‚úÖ Resultados de {model_name} guardados en {filepath}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas finales de KNN (mejor k)\n",
    "# ===================================\n",
    "\n",
    "\n",
    "results_knn = save_results(\n",
    "    \"KNN (k=3)\",\n",
    "    y_valid,\n",
    "    preds_knn,\n",
    "    \"../data/results_knn.csv\"\n",
    ")\n",
    "\n",
    "print(\"üìä Resultados finales KNN (mejor k)\")\n",
    "print(f\"Mejor k: {best_k}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n",
    "print(\"‚úÖ Resultados guardados en data/results_knn.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## **Paso 10. Conclusiones**\n",
    "\n",
    "- El rendimiento de KNN depende **fuertemente** de `k`.  \n",
    "- Este modelo necesita datos **escalados**.  \n",
    "- Funciona bien en datasets peque√±os y de baja dimensionalidad, pero en grandes puede ser costoso porque calcula distancias con todos los puntos.  \n",
    "\n",
    "\n",
    "\n",
    "üëâ En resumen: si KNN devuelve m√©tricas similares o mejores que regresi√≥n lineal y comparables a Random Forest/XGBoost, puede ser un candidato fuerte. Pero si empeora, ser√° menos competitivo.\n",
    "\n",
    "\n",
    "Compararemos este modelo con los dem√°s (Lineal, √Årboles, Random Forest, XGBoost, Ridge, Lasso, Elastic Net) en el notebook de **Comparaci√≥n Final de Modelos**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
