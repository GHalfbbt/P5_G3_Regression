{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **√Årboles de Decisi√≥n y Random Forest**\n",
    "\n",
    "En este notebook se entrena un modelo de **√°rbol de regresi√≥n (de Decisi√≥n y Random Forest)** para predecir la esperanza de vida a partir del dataset procesado (en el notebook `EDA_processed.ipynb`).\n",
    "\n",
    "En este notebook vamos a trabajar con **modelos basados en √°rboles**:\n",
    "\n",
    "- **√Årbol de Decisi√≥n (Decision Tree Regressor)**: sencillo de interpretar, pero propenso al sobreajuste.  \n",
    "- **Random Forest Regressor**: un ensamblado de √°rboles mediante bagging que reduce la varianza y mejora la generalizaci√≥n.  \n",
    "\n",
    "Adem√°s, exploraremos el concepto de **overfitting** con estos modelos.\n",
    "\n",
    "Del EDA_processed.ipynb exportamos dos datasets:\n",
    "\n",
    "- features_no_scaling.csv ‚Üí para √°rboles, Random Forest, XGBoost.\n",
    "\n",
    "- features_scaled.csv ‚Üí para modelos sensibles a la escala (Regresi√≥n Lineal, KNN, SVM...).\n",
    "Adem√°s del target_y.csv.\n",
    "\n",
    "Aqu√≠ usaremos el no escalado `features_no_scaling.csv`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **Paso 1. Importar librer√≠as y cargar datasets procesados**\n",
    "\n",
    "En este bloque cargamos las librer√≠as necesarias:\n",
    "\n",
    "- **pandas** ‚Üí manejo de datos.  \n",
    "- **scikit-learn** ‚Üí para la divisi√≥n del dataset (`train_test_split`), construcci√≥n de modelos de regresi√≥n (`DecisionTreeRegressor`, `RandomForestRegressor`) y c√°lculo de m√©tricas (`MAE`, `RMSE`, `R¬≤`).  \n",
    "- **plot_tree** ‚Üí permite visualizar gr√°ficamente un √°rbol de decisi√≥n entrenado.  \n",
    "- **matplotlib / seaborn / numpy** ‚Üí apoyo para gr√°ficos y c√°lculos num√©ricos.\n",
    "\n",
    "Con estas herramientas podremos entrenar, evaluar y visualizar el comportamiento de los modelos basados en √°rboles.\n",
    "\n",
    "En este paso tambi√©n importamos los datasets que ya preparamos en el notebook **EDA_processed**:\n",
    "\n",
    "- `features_no_scaling.csv` ‚Üí variables predictoras sin escalar (adecuadas para modelos basados en √°rboles).\n",
    "- `target_y.csv` ‚Üí variable objetivo (esperanza de vida).\n",
    "\n",
    "Aqu√≠ **no usamos el dataset escalado**, ya que √°rboles y Random Forest no necesitan normalizaci√≥n de variables.  \n",
    "Al final imprimimos las dimensiones de `X` e `y` para confirmar que todo est√° alineado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1. Importar librer√≠as\n",
    "# ===================================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# 2. Cargar datasets procesados no escalados \n",
    "# ===================================\n",
    "X_ns = pd.read_csv(\"../data/processed/features_no_scaling.csv\")\n",
    "y = pd.read_csv(\"../data/processed/target_y.csv\").squeeze()  # lo convertimos a Serie\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## **Paso 2. Divisi√≥n en entrenamiento y validaci√≥n**\n",
    "\n",
    "En este bloque:\n",
    "\n",
    "- Separamos el dataset en **conjunto de entrenamiento (80%)** y **conjunto de validaci√≥n (20%)**.  \n",
    "Esto nos permite entrenar el modelo con una parte de los datos y luego evaluar su rendimiento en datos que no ha visto antes.\n",
    "\n",
    "\n",
    "De esta manera, podremos comparar los algoritmos de forma justa y evitar errores de entrenamiento.\n",
    "\n",
    "- x = todas las columnas salvo la variable objetivo.\n",
    "- y = la variable objetivo.\n",
    "- train_test_split divide los datos en:\n",
    "  - x_train, y_train (80%) ‚Üí para entrenar el modelo.\n",
    "  - x_valid, y_valid (20%) ‚Üí para validar el modelo. \n",
    "  - random_state=42 ‚Üí asegura que la divisi√≥n sea reproducible.\n",
    "\n",
    "Este paso es obligatorio para aseguramos consistencia y poder comparar con en el resto de modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 2. Divisi√≥n train / validaci√≥n\n",
    "# ===================================\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_ns, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tama√±o entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Tama√±o validaci√≥n:\", X_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **Paso 3. √Årbol de Decisi√≥n baseline**\n",
    "\n",
    "En este paso entrenamos un **√Årbol de Decisi√≥n** con los par√°metros por defecto y evaluamos las m√©tricas.\n",
    "\n",
    "Un √°rbol de decisi√≥n divide los datos en nodos seg√∫n la variable que mejor reduce la **impureza** (en regresi√≥n, normalmente el **MSE** dentro de cada nodo).  \n",
    "Este baseline nos sirve como punto de partida para comparar con modelos m√°s complejos como **Random Forest** o **XGBoost**.\n",
    "\n",
    "M√©tricas que calculamos:\n",
    "- **RMSE (Root Mean Squared Error):** penaliza m√°s los errores grandes.  \n",
    "- **MAE (Mean Absolute Error):** error promedio en unidades originales (a√±os de esperanza de vida).  \n",
    "- **R¬≤:** proporci√≥n de varianza explicada (0 a 1 ‚Üí cuanto m√°s alto, mejor).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 3. √Årbol de Decisi√≥n (baseline)\n",
    "# ===================================\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "preds_tree = tree.predict(X_valid)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds_tree))\n",
    "mae = mean_absolute_error(y_valid, preds_tree)\n",
    "r2 = r2_score(y_valid, preds_tree)\n",
    "\n",
    "print(\"üìä Decision Tree (baseline)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## **Paso 4. Overfitting en √Årboles de Decisi√≥n: curva de aprendizaje con max_depth**\n",
    "\n",
    "\n",
    "Los **√°rboles de decisi√≥n** tienden a crecer hasta memorizar los datos de entrenamiento, lo que provoca **overfitting**.  \n",
    "\n",
    "Para analizarlo, variamos la **profundidad m√°xima (`max_depth`)** del √°rbol y graficamos los errores (RMSE) en:  \n",
    "- **Train (l√≠nea azul):** error sobre los datos de entrenamiento.  \n",
    "- **Valid (l√≠nea naranja):** error sobre datos no vistos (validaci√≥n).  \n",
    "\n",
    "\n",
    "### üìä Interpretaci√≥n de la curva de validaci√≥n (Decision Tree)\n",
    "\n",
    "\n",
    "En este gr√°fico vemos dos curvas:  \n",
    "- **Train RMSE** ‚Üí error en los datos de entrenamiento.  \n",
    "- **Valid RMSE** ‚Üí error en los datos de validaci√≥n. \n",
    "\n",
    "\n",
    "üîé **Qu√© significa la separaci√≥n de las curvas:**\n",
    "- Si **Train RMSE ‚â™ Valid RMSE**, el modelo est√° sobreajustando (overfitting).  \n",
    "- Si **ambos errores son altos**, el modelo est√° infraajustando (underfitting).  \n",
    "- El punto ideal es cuando **las curvas est√°n lo m√°s cercanas posible una de otra** y en un nivel bajo de error.  \n",
    "\n",
    "Esto indica un buen equilibrio entre **sesgo (bias)** y **varianza (variance)**.\n",
    "\n",
    " \n",
    "‚öôÔ∏è **Efecto de los hiperpar√°metros**:\n",
    "- **`max_depth ‚Üë`** o **aumenta** ‚Üí el √°rbol crece m√°s ‚Üí memoriza mejor el train (‚Üì error en train) pero aumenta el overfitting. El error en train baja mucho, pero en validaci√≥n empieza a subir a partir de cierto punto (signo de **sobreajuste**). \n",
    "- **`max_depth ‚Üì`** o es **muy bajo** ‚Üí el √°rbol o el modelo es demasiado simple (**underfitting**) ‚Üí puede aumentar el error en train (errores altos), pero mejora la generalizaci√≥n.  \n",
    "\n",
    "\n",
    "Lo que buscamos es un **compromiso entre complejidad y generalizaci√≥n**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 4. Overfitting en √Årboles de Decisi√≥n\n",
    "# ===================================\n",
    "\n",
    "train_errors, valid_errors = [], []\n",
    "depths = range(1, 21)\n",
    "\n",
    "for d in depths:\n",
    "    model = DecisionTreeRegressor(max_depth=d, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    \n",
    "    train_errors.append(np.sqrt(mean_squared_error(y_train, preds_train)))\n",
    "    valid_errors.append(np.sqrt(mean_squared_error(y_valid, preds_valid)))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(depths, train_errors, label=\"Train RMSE\", marker=\"o\")\n",
    "plt.plot(depths, valid_errors, label=\"Valid RMSE\", marker=\"o\")\n",
    "plt.xlabel(\"Profundidad del √°rbol (max_depth)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Overfitting en Decision Tree\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## **Paso 5. Random Forest (baseline)**\n",
    "\n",
    "Ahora entrenamos un Random Forest y evaluamos sus m√©tricas.  \n",
    "Este modelo combina muchos √°rboles entrenados sobre subconjuntos aleatorios de los datos, lo que reduce la varianza.\n",
    "\n",
    "\n",
    "Un **Random Forest** es un ensamble de √°rboles de decisi√≥n, entrena **muchos √°rboles de decisi√≥n** en paralelo, cada uno con:\n",
    "- Un subconjunto aleatorio de observaciones.  \n",
    "- Un subconjunto aleatorio de variables.  \n",
    "\n",
    "Esto introduce **diversidad en los √°rboles** y permite que, al promediar sus resultados, el modelo:\n",
    "- Reduzca la varianza (menos overfitting que un solo √°rbol).  \n",
    "- Generalice mejor en validaci√≥n.\n",
    "\n",
    "- Cada √°rbol se entrena sobre un subconjunto aleatorio de datos y de variables (**bagging**).  \n",
    "- Al combinar muchos √°rboles, se reducen los problemas de **overfitting** que vimos en el √°rbol simple.  \n",
    "- Es m√°s robusto y suele mejorar las m√©tricas de validaci√≥n.\n",
    "\n",
    "\n",
    "\n",
    "‚öôÔ∏è El hiperpar√°metro clave es `n_estimators`:\n",
    "- **Si `n_estimators ‚Üë`** ‚Üí m√°s √°rboles ‚Üí resultados m√°s estables pero mayor tiempo de c√≥mputo.  \n",
    "- **Si `n_estimators ‚Üì`** ‚Üí menos √°rboles ‚Üí m√°s r√°pido, pero menos robusto.  \n",
    "\n",
    "\n",
    "\n",
    "En este baseline usamos `n_estimators=200` √°rboles con par√°metros por defecto.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================\n",
    "# 5. Random Forest (baseline)\n",
    "# ===================================\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "preds_rf = rf.predict(X_valid)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds_rf))\n",
    "mae = mean_absolute_error(y_valid, preds_rf)\n",
    "r2 = r2_score(y_valid, preds_rf)\n",
    "\n",
    "print(\"üìä Random Forest (baseline)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## **Paso 6. Importancia de Variables**\n",
    "\n",
    "Los modelos basados en √°rboles permiten calcular la **importancia de las variables**:  \n",
    "permiten medir qu√© tan importante es cada variable, cu√°nto contribuye cada predictor a reducir el error en los nodos de decisi√≥n. \n",
    "\n",
    "Una ventaja de los modelos basados en √°rboles es que permiten calcular la **importancia de las variables**.  \n",
    "\n",
    "En el caso de **Random Forest**, la importancia se calcula promediando las reducciones de impureza de todos los √°rboles del ensamble.  \n",
    "\n",
    "- Una **importancia alta** indica que esa variable es muy influyente en las predicciones.  \n",
    "- Una **importancia baja** significa que la variable apenas aporta informaci√≥n.  \n",
    "\n",
    "\n",
    "üí° Recordatorio:  \n",
    "- El hiperpar√°metro `n_estimators` indica **cu√°ntos √°rboles de decisi√≥n** se entrenan en el Random Forest.  \n",
    "- A m√°s √°rboles, el modelo suele ser m√°s robusto y estable, aunque tambi√©n m√°s costoso en tiempo de entrenamiento.  \n",
    "- Un valor t√≠pico es 100‚Äì500 √°rboles, y aqu√≠ usamos `n_estimators=200`.  \n",
    "\n",
    "En este gr√°fico mostramos el **Top 20**.  \n",
    "Esto nos ayuda a:\n",
    "- Entender mejor el dataset.  \n",
    "- Posibles reducciones de dimensionalidad (quedarnos con las m√°s influyentes).  \n",
    "- Interpretar el modelo y explicar los resultados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 6. Importancia de Variables\n",
    "# ===================================\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"Variable\": X_train.columns,\n",
    "    \"Importancia\": rf.feature_importances_\n",
    "}).sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.barplot(\n",
    "    x=\"Importancia\", \n",
    "    y=\"Variable\", \n",
    "    data=importances.head(20), \n",
    "    hue=\"Variable\",          \n",
    "    dodge=False, \n",
    "    legend=False,            # ocultamos la leyenda\n",
    "    palette=\"Blues_r\"\n",
    ")\n",
    "plt.title(\"Top 20 variables m√°s importantes (Random Forest)\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()\n",
    "\n",
    "importances.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## **Paso 7. Ajuste de hiperpar√°metros en Random Forest**\n",
    "\n",
    "\n",
    "Hasta ahora hemos usado un **Random Forest baseline** con par√°metros por defecto (`n_estimators=200`).  \n",
    "Aunque este modelo ya mejora claramente al √°rbol de decisi√≥n simple, podemos explorar c√≥mo afecta variar algunos par√°metros clave:\n",
    "\n",
    "- **`n_estimators`**: n√∫mero de √°rboles en el ensamble. M√°s √°rboles reducen la varianza, pero aumentan el coste computacional.  \n",
    "- **`max_depth`**: profundidad m√°xima de los √°rboles. Controla la complejidad del modelo y previene overfitting.  \n",
    "- **`min_samples_split`**: n√∫mero m√≠nimo de muestras necesarias para dividir un nodo. Valores m√°s altos hacen que los √°rboles sean m√°s simples.  \n",
    "\n",
    "En este paso vamos a hacer una **b√∫squeda manual** variando `n_estimators` y observando c√≥mo cambia el RMSE en train y validaci√≥n.  \n",
    "\n",
    "üìä **Qu√© esperamos ver en el gr√°fico**:  \n",
    "- A medida que aumenta `n_estimators`, el error de validaci√≥n deber√≠a estabilizarse.  \n",
    "- Si las curvas de train y validaci√≥n est√°n cercanas y planas, significa que el modelo generaliza bien.  \n",
    "- Si hay una gran diferencia (train mucho mejor que validaci√≥n), significa que a√∫n hay cierto overfitting.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 7. Ajuste de hiperpar√°metros en Random Forest\n",
    "# ===================================\n",
    "train_errors, valid_errors = [], []\n",
    "n_estimators_range = range(10, 310, 20)  # probamos de 10 a 300 √°rboles\n",
    "## n_estimators_range = [50, 100, 200, 300, 500]\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    rf_model = RandomForestRegressor(random_state=42, n_estimators=n)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds_train = rf_model.predict(X_train)\n",
    "    preds_valid = rf_model.predict(X_valid)\n",
    "    \n",
    "    train_errors.append(np.sqrt(mean_squared_error(y_train, preds_train)))\n",
    "    valid_errors.append(np.sqrt(mean_squared_error(y_valid, preds_valid)))\n",
    "\n",
    "# Gr√°fico de curva de aprendizaje en funci√≥n de n_estimators\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(n_estimators_range, train_errors, label=\"Train RMSE\", marker=\"o\")\n",
    "plt.plot(n_estimators_range, valid_errors, label=\"Valid RMSE\", marker=\"o\")\n",
    "plt.xlabel(\"N√∫mero de √°rboles (n_estimators)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Curva de validaci√≥n - Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## **Paso 8. GridSearchCV para optimizaci√≥n de Random Forest**\n",
    "\n",
    "Hasta ahora usamos hiperpar√°metros por defecto.  \n",
    "Con **GridSearchCV** buscamos la mejor combinaci√≥n de par√°metros mediante validaci√≥n cruzada.  \n",
    "\n",
    "‚öôÔ∏è Principales hiperpar√°metros:\n",
    "- **`max_depth`**  \n",
    "  - ‚Üë profundidad ‚Üí m√°s complejo, riesgo de overfitting.  \n",
    "  - ‚Üì profundidad ‚Üí m√°s simple, riesgo de underfitting.  \n",
    "\n",
    "- **`min_samples_split`**  \n",
    "  - ‚Üë valor ‚Üí obliga a que los nodos tengan m√°s datos para dividirse ‚Üí √°rbol m√°s simple.  \n",
    "  - ‚Üì valor ‚Üí m√°s divisiones ‚Üí riesgo de overfitting.  \n",
    "\n",
    "- **`min_samples_leaf`**  \n",
    "  - ‚Üë valor ‚Üí hojas m√°s grandes ‚Üí √°rbol m√°s suave y general.  \n",
    "  - ‚Üì valor ‚Üí hojas con muy pocos datos ‚Üí riesgo de memorizar.  \n",
    "\n",
    "- **`n_estimators`**  \n",
    "  - ‚Üë m√°s √°rboles ‚Üí modelo m√°s robusto, pero m√°s lento.  \n",
    "  - ‚Üì menos √°rboles ‚Üí m√°s r√°pido, pero m√°s inestable.  \n",
    "\n",
    "üëâ El objetivo es **acercar las curvas de train y validaci√≥n** y reducir el RMSE. \n",
    "\n",
    "üìñ Explicaci√≥n de loq ue hacemos con GridSearchCV:\n",
    "\n",
    "  - GridSearchCV prueba todas las combinaciones de hiperpar√°metros en param_grid.\n",
    "  - Usa validaci√≥n cruzada (cv=5) para evaluar el rendimiento medio y reducir el riesgo de overfitting.\n",
    "  - El mejor modelo (best_estimator_) se reentrena con los mejores par√°metros encontrados.\n",
    "  - Luego lo evaluamos en nuestro conjunto de validaci√≥n independiente (hold-out) para confirmar.\n",
    "\n",
    "üí° Esto nos permite justificar mejor frente a XGBoost + Optuna:\n",
    "\n",
    "  - GridSearchCV = b√∫squeda exhaustiva (m√°s lento).\n",
    "  - Optuna = b√∫squeda inteligente con optimizaci√≥n bayesiana (m√°s r√°pido y escalable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 8. Optimizaci√≥n de Random Forest con GridSearchCV\n",
    "# ===================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos el modelo base\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Definimos la rejilla de hiperpar√°metros a explorar\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configuramos GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",  # usamos RMSE\n",
    "    cv=5,                                  # validaci√≥n cruzada 5-fold\n",
    "    n_jobs=-1,                             # usar todos los n√∫cleos\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entrenamos\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Mejores hiperpar√°metros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nüìä Mejor score (RMSE validaci√≥n):\")\n",
    "print(-grid_search.best_score_)\n",
    "\n",
    "# Evaluaci√≥n final en nuestro conjunto de validaci√≥n hold-out\n",
    "best_rf = grid_search.best_estimator_\n",
    "preds_best_rf = best_rf.predict(X_valid)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds_best_rf))\n",
    "mae = mean_absolute_error(y_valid, preds_best_rf)\n",
    "r2 = r2_score(y_valid, preds_best_rf)\n",
    "\n",
    "print(\"\\nüìä Random Forest Optimizado (validaci√≥n hold-out)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## **Paso 9. Heatmap de resultados de GridSearchCV**\n",
    "\n",
    "Visualizaci√≥n de resultados de GridSearchCV con un heatmap.\n",
    "\n",
    "\n",
    "üí° Este heatmap muestra c√≥mo cambian los errores medios de validaci√≥n cruzada (RMSE) en funci√≥n de dos hiperpar√°metros clave:\n",
    "\n",
    "- `n_estimators` = n√∫mero de √°rboles.\n",
    "- `max_depth` = profundidad m√°xima de cada √°rbol.\n",
    "- colores m√°s claros ‚Üí menor error ‚Üí mejor combinaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 9. Visualizaci√≥n de resultados de GridSearchCV\n",
    "# ===================================\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Extraemos solo los par√°metros y la media de la m√©trica (neg RMSE)\n",
    "pivot_table = results.pivot_table(\n",
    "    values=\"mean_test_score\",\n",
    "    index=\"param_max_depth\",\n",
    "    columns=\"param_n_estimators\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    -pivot_table,  # convertimos de \"neg RMSE\" a RMSE positivo\n",
    "    annot=True, fmt=\".3f\", cmap=\"Blues\"\n",
    ")\n",
    "plt.title(\"Heatmap RMSE promedio (GridSearchCV - Random Forest)\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## **Paso 10. Conclusiones √Årboles de Decisi√≥n vs. Random Forest Regressor**\n",
    "\n",
    "- **√Årbol de Decisi√≥n (baseline):**\n",
    "  - Modelo muy interpretable y r√°pido de entrenar.\n",
    "  - Sin embargo, tiende a **sobreajustar** cuando la profundidad aumenta.\n",
    "  - Vimos en la curva de validaci√≥n c√≥mo el error en train bajaba mucho, pero el de validaci√≥n empezaba a subir ‚Üí overfitting.\n",
    "\n",
    "- **Random Forest (baseline):**\n",
    "  - Combina muchos √°rboles entrenados en subconjuntos de datos (t√©cnica de **bagging**).\n",
    "  - Esto reduce la varianza y mejora la generalizaci√≥n.\n",
    "  - M√©tricas mejores que el √°rbol simple en validaci√≥n.\n",
    "\n",
    "- **Random Forest optimizado con GridSearchCV:**\n",
    "  - Ajustamos autom√°ticamente varios hiperpar√°metros:\n",
    "    - `n_estimators`: n√∫mero de √°rboles.\n",
    "    - `max_depth`: controla la complejidad.\n",
    "    - `min_samples_split` y `min_samples_leaf`: evitan nodos demasiado peque√±os.\n",
    "  - GridSearchCV hace una **b√∫squeda exhaustiva** de combinaciones y selecciona la mejor mediante validaci√≥n cruzada.\n",
    "  - El heatmap nos permiti√≥ ver c√≥mo ciertas combinaciones (`n_estimators` altos + `max_depth` medio) ofrecen los mejores resultados.\n",
    "  - Resultado: mejora del RMSE y R¬≤ respecto al baseline.\n",
    "\n",
    "üëâ Conclusi√≥n final: **Random Forest optimizado** ofrece un mejor equilibrio entre precisi√≥n y robustez frente a sobreajuste, siendo superior al √°rbol de decisi√≥n simple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## **Comparativa de modelos:** \n",
    "### √Årbol de Decisi√≥n, Random Forest baseline y Random Forest optimizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Comparativa final de m√©tricas\n",
    "# ===================================\n",
    "\n",
    "# Guardamos las m√©tricas en un diccionario\n",
    "results = {\n",
    "    \"Decision Tree\": {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_valid, preds_tree)),\n",
    "        \"MAE\": mean_absolute_error(y_valid, preds_tree),\n",
    "        \"R¬≤\": r2_score(y_valid, preds_tree)\n",
    "    },\n",
    "    \"Random Forest (baseline)\": {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_valid, preds_rf)),\n",
    "        \"MAE\": mean_absolute_error(y_valid, preds_rf),\n",
    "        \"R¬≤\": r2_score(y_valid, preds_rf)\n",
    "    },\n",
    "    \"Random Forest (optimizado)\": {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_valid, grid_search.best_estimator_.predict(X_valid))),\n",
    "        \"MAE\": mean_absolute_error(y_valid, grid_search.best_estimator_.predict(X_valid)),\n",
    "        \"R¬≤\": r2_score(y_valid, grid_search.best_estimator_.predict(X_valid))\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Convertimos a DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# --- Gr√°fico comparativo ---\n",
    "plt.figure(figsize=(10,6))\n",
    "results_df[[\"RMSE\",\"MAE\"]].plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Comparaci√≥n de RMSE y MAE entre modelos\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"M√©trica\")\n",
    "plt.show()\n",
    "\n",
    "# --- Gr√°fico R¬≤ ---\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(\n",
    "    x=results_df.index, \n",
    "    y=results_df[\"R¬≤\"], \n",
    "    hue=results_df.index,   # usamos la variable del eje como hue\n",
    "    palette=\"Blues_r\", \n",
    "    dodge=False, \n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Comparaci√≥n de R¬≤ entre modelos\")\n",
    "plt.ylabel(\"R¬≤\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "results_df\n",
    "\n",
    "# ===================================\n",
    "# Guardar resultados en CSV\n",
    "# ===================================\n",
    "\n",
    "# ===================================\n",
    "# Funci√≥n para guardar m√©tricas estandarizadas\n",
    "# ===================================\n",
    "def save_results(model_name, y_true, y_pred, filepath):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas (RMSE, MAE, R¬≤) y guarda en CSV estandarizado.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = pd.DataFrame([{\n",
    "        \"Modelo\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R¬≤\": r2\n",
    "    }])\n",
    "\n",
    "\n",
    "    results.to_csv(filepath, index=False)\n",
    "    print(f\"‚úÖ Resultados de {model_name} guardados en {filepath}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Guardar cada modelo por separado\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas en CSV para comparativa global\n",
    "# ===================================\n",
    "\n",
    "# Decision Tree\n",
    "results_tree = pd.DataFrame([{\n",
    "    \"Modelo\": \"Decision Tree\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_valid, preds_tree)),\n",
    "    \"MAE\": mean_absolute_error(y_valid, preds_tree),\n",
    "    \"R¬≤\": r2_score(y_valid, preds_tree)\n",
    "}])\n",
    "results_tree.to_csv(\"../data/results_tree.csv\", index=False)\n",
    "print(\"‚úÖ Resultados Decision Tree guardados en data/results_tree.csv\")\n",
    "\n",
    "# Random Forest (baseline)\n",
    "results_rf_base = pd.DataFrame([{\n",
    "    \"Modelo\": \"Random Forest (baseline)\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_valid, preds_rf)),\n",
    "    \"MAE\": mean_absolute_error(y_valid, preds_rf),\n",
    "    \"R¬≤\": r2_score(y_valid, preds_rf)\n",
    "}])\n",
    "results_rf_base.to_csv(\"../data/results_rf_baseline.csv\", index=False)\n",
    "print(\"‚úÖ Resultados Random Forest (baseline) guardados en data/results_rf_baseline.csv\")\n",
    "\n",
    "# Random Forest (optimizado con GridSearchCV)\n",
    "preds_rf_opt = grid_search.best_estimator_.predict(X_valid)\n",
    "results_rf_opt = pd.DataFrame([{\n",
    "    \"Modelo\": \"Random Forest (optimizado)\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_valid, preds_rf_opt)),\n",
    "    \"MAE\": mean_absolute_error(y_valid, preds_rf_opt),\n",
    "    \"R¬≤\": r2_score(y_valid, preds_rf_opt)\n",
    "}])\n",
    "results_rf_opt.to_csv(\"../data/results_rf_optimized.csv\", index=False)\n",
    "print(\"‚úÖ Resultados Random Forest (optimizado) guardados en data/results_rf_optimized.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
