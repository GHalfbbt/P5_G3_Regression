{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Ridge, Lasso y Elastic Net\n",
    "\n",
    "En este notebook aplicamos tres algoritmos de regresi√≥n lineal regularizada:\n",
    "\n",
    "- **Ridge Regression (L2):** penaliza el tama√±o de los coeficientes para evitar sobreajuste.  \n",
    "- **Lasso Regression (L1):** adem√°s de penalizar, puede llevar coeficientes a 0, haciendo selecci√≥n autom√°tica de variables.  \n",
    "- **Elastic Net (L1 + L2):** combina Ridge y Lasso, equilibrando estabilidad y selecci√≥n de variables.\n",
    "\n",
    "Usamos el dataset **escalado** porque estos algoritmos son sensibles a la magnitud de las variables.  \n",
    "Al final compararemos m√©tricas y veremos c√≥mo afecta la regularizaci√≥n al modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **Paso 1. Importaci√≥n de librer√≠as**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1. Importar librer√≠as\n",
    "# ===================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Paso 2. Cargar datasets procesados (escalados)**\n",
    "\n",
    "En este paso cargamos el dataset procesado y **escalado** desde el notebook `EDA_processed`.  \n",
    "Tambi√©n separamos los datos en entrenamiento y validaci√≥n (80/20). \n",
    "\n",
    "Por eso cargamos el dataset **escalado** (`features_scaled.csv`), generado en el notebook `EDA_processed.ipynb` con `StandardScaler`.  \n",
    "\n",
    "Esto asegura que todas las variables tengan media 0 y varianza 1, evitando que variables con unidades m√°s grandes (por ejemplo PIB o gasto sanitario) dominen a otras m√°s peque√±as.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 2. Cargar dataset escalado \n",
    "# ===================================\n",
    "\n",
    "X_scaled = pd.read_csv(\"../data/processed/features_scaled.csv\")\n",
    "y = pd.read_csv(\"../data/processed/target_y.csv\").squeeze()  # convertir a Serie\n",
    "\n",
    "\n",
    "# Divisi√≥n train / validaci√≥n\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tama√±o entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Tama√±o validaci√≥n:\", X_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **Paso 3. Ridge Regression (L2)**\n",
    "\n",
    "Ridge a√±ade una penalizaci√≥n L2 a la regresi√≥n lineal, reduciendo el tama√±o de los coeficientes.  \n",
    "Esto ayuda a **controlar el sobreajuste** y mejorar la estabilidad del modelo cuando hay multicolinealidad.  \n",
    "No elimina variables, pero las reduce en magnitud.\n",
    "\n",
    "Entrenamos el modelo con un valor inicial de `alpha=1.0` y calculamos las m√©tricas:\n",
    "- **RMSE**: error cuadr√°tico medio (ra√≠z).  \n",
    "- **MAE**: error absoluto medio.  \n",
    "- **R¬≤**: proporci√≥n de la varianza explicada.\n",
    "\n",
    "\n",
    "### Interpretaci√≥n: Ridge Regression\n",
    "\n",
    "- Ridge ha penalizado los coeficientes m√°s grandes, reduciendo su magnitud.  \n",
    "- Esto ayuda a controlar el **sobreajuste** y estabiliza el modelo frente a variables correlacionadas.  \n",
    "- Observando las m√©tricas:  \n",
    "  - **RMSE bajo** ‚Üí buenas predicciones en validaci√≥n.  \n",
    "  - **MAE** nos da el error promedio en unidades originales (a√±os de esperanza de vida).  \n",
    "  - **R¬≤** cercano a 1 indica qu√© porcentaje de la variabilidad se explica por el modelo.  \n",
    "\n",
    "Si Ridge mejora respecto a la **Regresi√≥n Lineal simple**, significa que la regularizaci√≥n est√° ayudando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 3. Ridge Regression\n",
    "# ===================================\n",
    "ridge = Ridge(alpha=1.0, random_state=42)  # alpha controla la regularizaci√≥n\n",
    "ridge.fit(X_train, y_train)\n",
    "preds_ridge = ridge.predict(X_valid)\n",
    "\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_valid, preds_ridge))\n",
    "mae_ridge = mean_absolute_error(y_valid, preds_ridge)\n",
    "r2_ridge = r2_score(y_valid, preds_ridge)\n",
    "\n",
    "print(\"üìä Ridge Regression\")\n",
    "print(f\"RMSE: {rmse_ridge:.3f}\")\n",
    "print(f\"MAE: {mae_ridge:.3f}\")\n",
    "print(f\"R¬≤: {r2_ridge:.3f}\")\n",
    "\n",
    "# --- Gr√°fico: valores reales vs predichos ---\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_valid, y=preds_ridge, alpha=0.5)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--')\n",
    "plt.title(\"Ridge: Valores reales vs predichos\")\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## **Paso 4. Lasso Regression (L1)**\n",
    "\n",
    "Lasso, no solo penaliza como Ridge, sino a√±ade una penalizaci√≥n L1 que fuerza a algunos coeficientes a ser **exactamente 0**.  \n",
    "Esto significa que realiza **selecci√≥n autom√°tica de variables**, dejando solo las m√°s relevantes.\n",
    "\n",
    "üëâ Entrenamos con `alpha=0.1` y calculamos las m√©tricas.  \n",
    "Adem√°s, podemos observar qu√© variables han quedado con coeficientes 0.\n",
    "\n",
    "### Interpretaci√≥n: Lasso Regression\n",
    "\n",
    "- Lasso no solo penaliza como Ridge, sino que tambi√©n **elimina variables irrelevantes** (coeficientes = 0).  \n",
    "- Esto lo convierte en un m√©todo √∫til para **selecci√≥n autom√°tica de caracter√≠sticas**.  \n",
    "- F√≠jate en la salida: cu√°ntas variables fueron eliminadas.  \n",
    "\n",
    "- Si el RMSE o R¬≤ no mejoran mucho respecto a Ridge, puede significar que casi todas las variables son √∫tiles.  \n",
    "- Si mejora y adem√°s reduce variables, nos est√° dando un modelo **m√°s simple y explicativo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 4. Lasso Regression\n",
    "# ===================================\n",
    "lasso = Lasso(alpha=0.01, random_state=42)  # alpha mayor ‚Üí m√°s coeficientes llevados a cero\n",
    "lasso.fit(X_train, y_train)\n",
    "preds_lasso = lasso.predict(X_valid)\n",
    "\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_valid, preds_lasso))\n",
    "mae_lasso = mean_absolute_error(y_valid, preds_lasso)\n",
    "r2_lasso = r2_score(y_valid, preds_lasso)\n",
    "\n",
    "print(\"üìä Lasso Regression\")\n",
    "print(f\"RMSE: {rmse_lasso:.3f}\")\n",
    "print(f\"MAE: {mae_lasso:.3f}\")\n",
    "print(f\"R¬≤: {r2_lasso:.3f}\")\n",
    "\n",
    "\n",
    "# Variables eliminadas por Lasso\n",
    "coef_lasso = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "print(\"\\nN√∫mero de variables eliminadas por Lasso:\", (coef_lasso == 0).sum())\n",
    "\n",
    "\n",
    "# --- Gr√°fico: valores reales vs predichos ---\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_valid, y=preds_lasso, alpha=0.5, color=\"orange\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--')\n",
    "plt.title(\"Lasso: Valores reales vs predichos\")\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## **Paso 5. Elastic Net (L1 + L2)**\n",
    "\n",
    "Elastic Net combina las penalizaciones L1 (Lasso) y L2 (Ridge).  \n",
    "Controla dos hiperpar√°metros:\n",
    "- **alpha**: fuerza de la regularizaci√≥n.  \n",
    "- **l1_ratio**: proporci√≥n entre L1 y L2 (ejemplo: 0.5 = mitad Lasso, mitad Ridge).\n",
    "\n",
    "üëâ Entrenamos con `alpha=0.1` y `l1_ratio=0.5` y calculamos las m√©tricas.\n",
    "\n",
    "\n",
    "### Interpretaci√≥n: Elastic Net\n",
    "\n",
    "- Elastic Net combina lo mejor de Ridge y Lasso:  \n",
    "  - **L2** para estabilizar el modelo frente a multicolinealidad.  \n",
    "  - **L1** para eliminar variables innecesarias.  \n",
    "- El hiperpar√°metro `l1_ratio` define el equilibrio:  \n",
    "  - 0.0 ‚Üí Ridge puro.  \n",
    "  - 1.0 ‚Üí Lasso puro.  \n",
    "  - 0.5 ‚Üí mezcla equilibrada.  \n",
    "\n",
    "Si Elastic Net logra m√©tricas similares o mejores que Ridge y Lasso, suele ser una **opci√≥n m√°s robusta**, ya que se adapta mejor a distintos escenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 5. Elastic Net\n",
    "# ===================================\n",
    "en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=42)  \n",
    "# l1_ratio=0.5 ‚Üí combina Ridge (L2) y Lasso (L1) al 50%\n",
    "en.fit(X_train, y_train)\n",
    "preds_en = en.predict(X_valid)\n",
    "\n",
    "rmse_en = np.sqrt(mean_squared_error(y_valid, preds_en))\n",
    "mae_en = mean_absolute_error(y_valid, preds_en)\n",
    "r2_en = r2_score(y_valid, preds_en)\n",
    "\n",
    "print(\"üìä Elastic Net\")\n",
    "print(f\"RMSE: {rmse_en:.3f}\")\n",
    "print(f\"MAE: {mae_en:.3f}\")\n",
    "print(f\"R¬≤: {r2_en:.3f}\")\n",
    "\n",
    "# --- Gr√°fico: valores reales vs predichos ---\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_valid, y=preds_en, alpha=0.5, color=\"green\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--')\n",
    "plt.title(\"Elastic Net: Valores reales vs predichos\")\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## **Paso 6. Comparativa visual de m√©tricas entre modelos**\n",
    "\n",
    "Vamos a comparar los resultados de **Ridge, Lasso y Elastic Net** en un gr√°fico de barras.  \n",
    "Esto nos permite ver r√°pidamente cu√°l tiene mejor desempe√±o en RMSE, MAE y R¬≤.\n",
    "\n",
    "\n",
    "### üîé Interpretaci√≥n: Comparativa Ridge vs Lasso vs Elastic Net\n",
    "\n",
    "- El gr√°fico muestra los valores de **RMSE, MAE y R¬≤** para los tres algoritmos.  \n",
    "- Puntos clave a observar:  \n",
    "  - ¬øQu√© modelo tiene el **menor RMSE**? ‚Üí predicciones m√°s precisas.  \n",
    "  - ¬øQu√© modelo tiene el **mayor R¬≤**? ‚Üí mejor capacidad explicativa.  \n",
    "  - Lasso podr√≠a perder algo de precisi√≥n si elimin√≥ variables importantes.  \n",
    "  - Ridge puede ser m√°s estable cuando muchas variables est√°n correlacionadas.  \n",
    "  - Elastic Net es un t√©rmino medio que muchas veces ofrece un **balance √≥ptimo**.\n",
    "\n",
    "üëâ Si los tres modelos dan m√©tricas similares, Ridge suele ser suficiente.  \n",
    "üëâ Si hay muchas variables irrelevantes, Lasso o Elastic Net pueden ser mejores.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 6. Comparativa de m√©tricas entre modelos\n",
    "# ===================================\n",
    "results = pd.DataFrame({\n",
    "    \"Modelo\": [\"Ridge\", \"Lasso\", \"Elastic Net\"],\n",
    "    \"RMSE\": [\n",
    "        np.sqrt(mean_squared_error(y_valid, preds_ridge)),\n",
    "        np.sqrt(mean_squared_error(y_valid, preds_lasso)),\n",
    "        np.sqrt(mean_squared_error(y_valid, preds_elastic)),\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mean_absolute_error(y_valid, preds_ridge),\n",
    "        mean_absolute_error(y_valid, preds_lasso),\n",
    "        mean_absolute_error(y_valid, preds_elastic),\n",
    "    ],\n",
    "    \"R2\": [\n",
    "        r2_score(y_valid, preds_ridge),\n",
    "        r2_score(y_valid, preds_lasso),\n",
    "        r2_score(y_valid, preds_elastic),\n",
    "    ]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "results.set_index(\"Modelo\")[[\"RMSE\",\"MAE\",\"R2\"]].plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Comparativa de Ridge, Lasso y Elastic Net\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## **Nota sobre el ajuste de hiperpar√°metros**\n",
    "\n",
    "En este notebook usamos valores fijos de `alpha` y `l1_ratio`, pero podr√≠an ajustarse autom√°ticamente usando **GridSearchCV** o **Optuna**, como hacemos en Random Forest y XGBoost.  \n",
    "\n",
    "- Para **Ridge y Lasso**, se suele ajustar `alpha`.  \n",
    "- Para **Elastic Net**, se ajustan tanto `alpha` como `l1_ratio`.  \n",
    "\n",
    "Esto permitir√≠a encontrar la mejor combinaci√≥n que minimice RMSE o maximice R¬≤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## **Paso 7 ‚Äì Optimizaci√≥n de hiperpar√°metros con GridSearchCV**\n",
    "\n",
    "Hasta ahora usamos valores fijos de `alpha` (y `l1_ratio` en Elastic Net).  \n",
    "Sin embargo, estos hiperpar√°metros pueden influir mucho en el rendimiento del modelo.\n",
    "\n",
    "üëâ Con **GridSearchCV** exploramos diferentes combinaciones de par√°metros:  \n",
    "- Para **Ridge y Lasso** ‚Üí `alpha` (fuerza de regularizaci√≥n).  \n",
    "- Para **Elastic Net** ‚Üí `alpha` y `l1_ratio` (equilibrio entre L1 y L2).  \n",
    "\n",
    "### Qu√© esperamos:\n",
    "- Valores de `alpha` muy bajos ‚âà modelo casi igual a regresi√≥n lineal.  \n",
    "- Valores de `alpha` muy altos ‚âà modelo demasiado restringido, baja capacidad de predicci√≥n.  \n",
    "- En Elastic Net, ver c√≥mo el balance `l1_ratio` afecta al resultado.  \n",
    "\n",
    "üìä Mostraremos un heatmap de RMSE promedio para cada modelo y concluiremos qu√© combinaci√≥n es m√°s aceptable para nuestro dataset de **Esperanza de Vida**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 7. Optimizaci√≥n con GridSearchCV\n",
    "# ===================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos el espacio de b√∫squeda\n",
    "param_grid_ridge = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "param_grid_lasso = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "param_grid_enet = {\n",
    "    \"alpha\": [0.01, 0.1, 1, 10],\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Modelos\n",
    "ridge = Ridge(random_state=42)\n",
    "lasso = Lasso(random_state=42, max_iter=5000)\n",
    "elastic = ElasticNet(random_state=42, max_iter=5000)\n",
    "\n",
    "# GridSearchCV\n",
    "ridge_search = GridSearchCV(ridge, param_grid_ridge, cv=5,\n",
    "                            scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "lasso_search = GridSearchCV(lasso, param_grid_lasso, cv=5,\n",
    "                            scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "enet_search = GridSearchCV(elastic, param_grid_enet, cv=5,\n",
    "                           scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "\n",
    "# Entrenar b√∫squedas\n",
    "ridge_search.fit(X_train, y_train)\n",
    "lasso_search.fit(X_train, y_train)\n",
    "enet_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar mejores par√°metros\n",
    "print(\"üìä Mejores par√°metros encontrados:\")\n",
    "print(\"Ridge:\", ridge_search.best_params_, \"‚Üí RMSE:\", -ridge_search.best_score_)\n",
    "print(\"Lasso:\", lasso_search.best_params_, \"‚Üí RMSE:\", -lasso_search.best_score_)\n",
    "print(\"Elastic Net:\", enet_search.best_params_, \"‚Üí RMSE:\", -enet_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### üîé Interpretaci√≥n de resultados\n",
    "\n",
    "- Cada b√∫squeda devuelve el valor de `alpha` (y `l1_ratio` en Elastic Net) que **minimiza el RMSE promedio en validaci√≥n cruzada**.\n",
    "- Un menor RMSE significa que el modelo generaliza mejor.\n",
    "- Si:\n",
    "  - **Ridge** es el ganador ‚Üí hay multicolinealidad pero todas las variables aportan.  \n",
    "  - **Lasso** es el ganador ‚Üí algunas variables son irrelevantes y conviene eliminarlas.  \n",
    "  - **Elastic Net** gana ‚Üí necesitamos un balance entre ambos mundos.  \n",
    "\n",
    "üëâ Para este dataset (Esperanza de Vida), donde hay muchas variables correlacionadas pero casi todas con relevancia, **Ridge o Elastic Net suelen ser m√°s adecuados**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## **Paso 8 ‚Äì Heatmap de Elastic Net (Œ± vs l1_ratio)**\n",
    "\n",
    "Para visualizar c√≥mo afectan los hiperpar√°metros de **Elastic Net** al rendimiento,\n",
    "vamos a generar un **heatmap de RMSE promedio** seg√∫n la combinaci√≥n de:\n",
    "\n",
    "- **Œ± (alpha):** controla la fuerza de regularizaci√≥n.  \n",
    "- **l1_ratio:** equilibrio entre penalizaci√≥n L1 (como Lasso) y L2 (como Ridge).  \n",
    "\n",
    "### Interpretaci√≥n esperada:\n",
    "- **Valores peque√±os de Œ±** ‚Üí modelo se parece a una regresi√≥n lineal (menos regularizaci√≥n).  \n",
    "- **Valores grandes de Œ±** ‚Üí modelo muy penalizado, peor rendimiento.  \n",
    "- **l1_ratio cercano a 1** ‚Üí se comporta m√°s como Lasso (selecci√≥n de variables).  \n",
    "- **l1_ratio cercano a 0** ‚Üí se comporta m√°s como Ridge (todas las variables cuentan).  \n",
    "\n",
    "üìä El heatmap nos permitir√° ver en qu√© zona (Œ±, l1_ratio) el modelo obtiene menor RMSE (mejor desempe√±o).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 8. Heatmap comparativo de m√©tricas (Ridge, Lasso, Elastic Net)\n",
    "# ===================================\n",
    "\n",
    "# Creamos un DataFrame con las m√©tricas\n",
    "metrics = pd.DataFrame({\n",
    "    \"Ridge\": [rmse_ridge, mae_ridge, r2_ridge],\n",
    "    \"Lasso\": [rmse_lasso, mae_lasso, r2_lasso],\n",
    "    \"Elastic Net\": [rmse_en, mae_en, r2_en]\n",
    "}, index=[\"RMSE\", \"MAE\", \"R¬≤\"])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(metrics, annot=True, fmt=\".3f\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Comparaci√≥n de m√©tricas entre Ridge, Lasso y Elastic Net\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylabel(\"M√©trica\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## **Paso 9 ‚Äì Conclusiones: Ridge, Lasso y Elastic Net**\n",
    "\n",
    "Tras entrenar y evaluar los tres modelos de regularizaci√≥n, podemos destacar lo siguiente:\n",
    "\n",
    "### üîπ Ridge\n",
    "- Penaliza los coeficientes grandes con una regularizaci√≥n **L2**.  \n",
    "- Tiende a **mantener todas las variables**, pero reduciendo sus pesos.  \n",
    "- Funciona bien cuando muchas variables tienen **efecto peque√±o pero distribuido**.  \n",
    "- En este dataset, Ridge suele mostrar un desempe√±o estable y reduce el sobreajuste respecto a la regresi√≥n lineal simple.\n",
    "\n",
    "### üîπ Lasso\n",
    "- Usa penalizaci√≥n **L1**, que fuerza a algunos coeficientes a ser exactamente **0**.  \n",
    "- Act√∫a como un **selector autom√°tico de variables**.  \n",
    "- Puede ser √∫til en datasets con muchas variables irrelevantes o redundantes.  \n",
    "- En este caso, Lasso probablemente elimine algunas variables menos influyentes en la predicci√≥n de la esperanza de vida.  \n",
    "- Si el RMSE es mayor que en Ridge, significa que su efecto de selecci√≥n no aporta mucho valor aqu√≠.\n",
    "\n",
    "### üîπ Elastic Net\n",
    "- Combina **L1 y L2** mediante el hiperpar√°metro `l1_ratio`.  \n",
    "- Es flexible: puede comportarse como Ridge (cuando l1_ratio‚Üí0) o como Lasso (cuando l1_ratio‚Üí1).  \n",
    "- Es √∫til cuando hay **muchas variables correlacionadas** y algunas deben ser eliminadas.  \n",
    "- Con el heatmap vimos en qu√© zona de par√°metros el RMSE es menor: ese equilibrio nos dice qu√© proporci√≥n de Ridge/Lasso es m√°s adecuada.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Comparaci√≥n global en este dataset\n",
    "- **Ridge** ‚Üí suele dar el mejor equilibrio entre sesgo y varianza.  \n",
    "- **Lasso** ‚Üí puede ser menos preciso en RMSE, pero ofrece interpretabilidad (elige pocas variables).  \n",
    "- **Elastic Net** ‚Üí permite afinar entre ambos mundos, siendo m√°s robusto si hay multicolinealidad en las variables.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Para este dataset de esperanza de vida (con un n√∫mero moderado de features ya preprocesadas):  \n",
    "- **Ridge** suele ser la opci√≥n m√°s s√≥lida en m√©tricas.  \n",
    "- **Lasso** puede ser interesante para simplificar el modelo.  \n",
    "- **Elastic Net** es una buena alternativa si se quiere un balance y explorar la importancia de variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## **Paso 10 ‚Äì Comparaci√≥n de m√©tricas entre Ridge, Lasso y Elastic Net**\n",
    "\n",
    "Para comparar de forma clara los tres modelos, recopilamos las m√©tricas principales:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** mide el error promedio en las predicciones, penalizando m√°s los errores grandes.  \n",
    "- **MAE (Mean Absolute Error):** mide el error promedio absoluto, m√°s robusto frente a outliers.  \n",
    "- **R¬≤ (Coeficiente de determinaci√≥n):** indica la proporci√≥n de varianza explicada por el modelo (m√°s cercano a 1 es mejor).\n",
    "\n",
    "La siguiente tabla resume los resultados obtenidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 10. Comparaci√≥n de m√©tricas entre modelos\n",
    "# ===================================\n",
    "results = pd.DataFrame({\n",
    "    \"Modelo\": [\"Ridge\", \"Lasso\", \"Elastic Net\"],\n",
    "    \"RMSE\": [rmse_ridge, rmse_lasso, rmse_en],\n",
    "    \"MAE\": [mae_ridge, mae_lasso, mae_en],\n",
    "    \"R¬≤\": [r2_ridge, r2_lasso, r2_en]\n",
    "})\n",
    "\n",
    "# Mostrar tabla ordenada por RMSE (menor es mejor)\n",
    "results = results.sort_values(by=\"RMSE\")\n",
    "display(results)\n",
    "\n",
    "# Gr√°fico comparativo\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"Modelo\", y=\"RMSE\", data=results, hue=\"Modelo\", legend=False, palette=\"Blues_r\")\n",
    "plt.title(\"Comparaci√≥n de modelos: RMSE\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar resultados en CSV\n",
    "# ===================================\n",
    "\n",
    "# ===================================\n",
    "# Funci√≥n para guardar m√©tricas estandarizadas\n",
    "# ===================================\n",
    "def save_results(model_name, y_true, y_pred, filepath):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas (RMSE, MAE, R¬≤) y guarda en CSV estandarizado.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = pd.DataFrame([{\n",
    "        \"Modelo\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R¬≤\": r2\n",
    "    }])\n",
    "\n",
    "    results.to_csv(filepath, index=False)\n",
    "    print(f\"‚úÖ Resultados de {model_name} guardados en {filepath}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas Ridge\n",
    "# ===================================\n",
    "results_ridge = save_results(\n",
    "    \"Ridge\",\n",
    "    y_valid,\n",
    "    preds_ridge,\n",
    "    \"../data/results_ridge.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas Lasso\n",
    "# ===================================\n",
    "results_lasso = save_results(\n",
    "    \"Lasso\",\n",
    "    y_valid,\n",
    "    preds_lasso,\n",
    "    \"../data/results_lasso.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas Elastic Net\n",
    "# ===================================\n",
    "results_en = save_results(\n",
    "    \"Elastic Net\",\n",
    "    y_valid,\n",
    "    preds_en,\n",
    "    \"../data/results_elasticnet.csv\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
