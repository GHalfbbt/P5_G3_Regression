{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **Linear Regression - Life Expectancy Prediction**\n",
    "\n",
    "En este notebook se entrena un modelo de **Regresi√≥n Lineal** para predecir la esperanza de vida a partir del dataset procesado (en el notebook `EDA_processed.ipynb`).  \n",
    "La regresi√≥n lineal se utiliza como un modelo **baseline**, ya que es sencillo de interpretar y sirve como referencia frente a modelos m√°s complejos.\n",
    "\n",
    "Del EDA_processed.ipynb exportamos dos datasets:\n",
    "\n",
    "- features_no_scaling.csv ‚Üí para √°rboles, Random Forest, XGBoost.\n",
    "\n",
    "- features_scaled.csv ‚Üí para modelos sensibles a la escala (Regresi√≥n Lineal, KNN, SVM...).\n",
    "Adem√°s del target_y.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **Paso 1. Importaci√≥n de librer√≠as y carga de datasets procesados**\n",
    "\n",
    "**Sobre el dataset usado:**\n",
    "En este notebook trabajamos con **Regresi√≥n Lineal**, un modelo sensible a la magnitud de las variables.  \n",
    "Por eso cargamos el dataset **escalado** (`features_scaled.csv`), generado en el notebook `EDA_processed.ipynb` con `StandardScaler`.  \n",
    "\n",
    "Esto asegura que todas las variables tengan media 0 y varianza 1, evitando que variables con unidades m√°s grandes (por ejemplo PIB o gasto sanitario) dominen a otras m√°s peque√±as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1. Importar librer√≠as\n",
    "# ===================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizaci√≥n m√°s est√©tica\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# ===================================\n",
    "# Cargar datasets procesados\n",
    "# ===================================\n",
    "X_scaled = pd.read_csv(\"../data/processed/features_scaled.csv\")\n",
    "y = pd.read_csv(\"../data/processed/target_y.csv\").squeeze()  # convertir en Serie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## **Paso 2. Divisi√≥n en entrenamiento y validaci√≥n**\n",
    "\n",
    "En este bloque:\n",
    "\n",
    "- Separamos el dataset en **conjunto de entrenamiento (80%)** y **conjunto de validaci√≥n (20%)**.  \n",
    "Esto nos permite entrenar el modelo con una parte de los datos y luego evaluar su rendimiento en datos que no ha visto antes.\n",
    "\n",
    "\n",
    "De esta manera, podremos comparar los algoritmos de forma justa y evitar errores de entrenamiento.\n",
    "\n",
    "- x = todas las columnas salvo la variable objetivo.\n",
    "- y = la variable objetivo.\n",
    "- train_test_split divide los datos en:\n",
    "  - x_train, y_train (80%) ‚Üí para entrenar el modelo.\n",
    "  - x_valid, y_valid (20%) ‚Üí para validar el modelo. \n",
    "  - random_state=42 ‚Üí asegura que la divisi√≥n sea reproducible.\n",
    "\n",
    "Este paso es obligatorio para poder comparar modelos en condiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 2. Divisi√≥n train/validaci√≥n\n",
    "# ===================================\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"üîπ Dataset escalado\")\n",
    "print(\"Tama√±o entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Tama√±o validaci√≥n:\", X_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **Paso 3. Entrenamiento y evaluaci√≥n del modelo**\n",
    "\n",
    "\n",
    "En este bloque entrenamos el modelo de **Regresi√≥n Lineal** con el conjunto de entrenamiento y lo evaluamos con el conjunto de validaci√≥n.  \n",
    "\n",
    "1. **Entrenamiento (`fit`)**:  \n",
    "   Ajustamos el modelo a los datos de entrenamiento (`X_train`, `y_train`).  \n",
    "   Esto significa que el algoritmo calcula los coeficientes (pesos) de la ecuaci√≥n lineal que mejor explican la relaci√≥n entre las variables independientes y la esperanza de vida.\n",
    "\n",
    "2. **Predicci√≥n (`predict`)**:  \n",
    "   Usamos los datos de validaci√≥n (`X_valid`) para que el modelo prediga valores de `y`.  \n",
    "   Estos valores predichos (`preds`) se comparan con los valores reales (`y_valid`).\n",
    "\n",
    "3. **M√©tricas de evaluaci√≥n**:  \n",
    "   - **RMSE (Root Mean Squared Error)**: error cuadr√°tico medio en la misma escala que la variable objetivo. Cuanto m√°s bajo, mejor.  \n",
    "     Penaliza m√°s los errores grandes, por eso es √∫til para detectar desviaciones fuertes.  \n",
    "   - **MAE (Mean Absolute Error)**: error absoluto medio. Es m√°s robusto frente a valores at√≠picos que el RMSE.  \n",
    "     Representa, en promedio, cu√°nto se equivoca el modelo al predecir.  \n",
    "   - **R¬≤ (Coeficiente de determinaci√≥n)**: mide qu√© proporci√≥n de la variabilidad de la variable objetivo se explica con el modelo.  \n",
    "     Su valor est√° entre 0 y 1 (aunque puede ser negativo si el modelo es muy malo). Valores cercanos a 1 indican un buen ajuste.\n",
    "\n",
    "En resumen:  \n",
    "- Un **RMSE y MAE bajos** indican que las predicciones son precisas.  \n",
    "- Un **R¬≤ alto** indica que el modelo explica gran parte de la variabilidad en la esperanza de vida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 3. Entrenar y evaluar modelo\n",
    "# ===================================\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "preds = lr.predict(X_valid)\n",
    "\n",
    "\n",
    "\n",
    "# M√©tricas\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "mae = mean_absolute_error(y_valid, preds)\n",
    "r2 = r2_score(y_valid, preds)\n",
    "\n",
    "print(\"üìä Linear Regression (con datos escalados)\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"R¬≤: {r2:.3f}\")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Funci√≥n para guardar m√©tricas estandarizadas\n",
    "# ===================================\n",
    "def save_results(model_name, y_true, y_pred, filepath):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas (RMSE, MAE, R¬≤) y guarda en CSV estandarizado.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = pd.DataFrame([{\n",
    "        \"Modelo\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R¬≤\": r2\n",
    "    }])\n",
    "\n",
    "    results.to_csv(filepath, index=False)\n",
    "    print(f\"‚úÖ Resultados de {model_name} guardados en {filepath}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# Guardar m√©tricas Linear Regression\n",
    "# ===================================\n",
    "results_lr = save_results(\n",
    "    \"Linear Regression\",\n",
    "    y_valid,\n",
    "    preds,\n",
    "    \"../data/results_linear.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## **Paso 4. Visualizaci√≥n de resultados**\n",
    "\n",
    "Este gr√°fico muestra la relaci√≥n entre los valores reales de la esperanza de vida y las predicciones del modelo.  \n",
    "- Si el modelo fuera perfecto, todos los puntos caer√≠an sobre la l√≠nea roja diagonal.  \n",
    "- La dispersi√≥n alrededor de la l√≠nea refleja el error de predicci√≥n.  \n",
    "\n",
    "\n",
    "**¬øPor qu√© seguimos viendo puntos alejados de la recta si \"limpiamos\" Outliers en el EDA inicial?**\n",
    "\n",
    "### Outliers ‚â† todo punto lejos de la recta de regresi√≥n\n",
    "\n",
    "En el **EDA** aplicamos un tratamiento de *outliers* usando reglas como **IQR (rango intercuart√≠lico)** o **boxplots** sobre las variables.  \n",
    "\n",
    "Eso sirve para detectar valores extremos en cada **variable independiente (features)** de forma **univariada**.  \n",
    "\n",
    "Sin embargo, cuando ajustamos una **regresi√≥n lineal**, los *puntos alejados de la recta* que vemos son **residuos grandes** (casos donde el modelo no predijo bien).  \n",
    "\n",
    "üëâ No siempre esos puntos son *outliers* en las features: a veces son valores leg√≠timos que simplemente no siguen la relaci√≥n lineal.\n",
    "\n",
    "\n",
    "### Qu√© puede estar pasando aqu√≠\n",
    "- Eliminamos los outliers univariados, pero **no necesariamente los outliers multivariados** (casos raros en combinaci√≥n de varias variables).  \n",
    "- La **regresi√≥n lineal es muy sensible**: aunque un dato no sea extremo en cada feature, puede ser influyente y alejarse de la recta.  \n",
    "\n",
    "\n",
    "### Opciones que tenemos\n",
    "1. **Revisar los residuos**: graficar `y_valid vs. preds` y un histograma de los residuos.  \n",
    "   - Si vemos muchos puntos dispersos lejos, el modelo no est√° capturando bien la complejidad.  \n",
    "2. **Usar m√©tricas robustas (MAE)** adem√°s de RMSE, porque el RMSE se dispara con outliers.  \n",
    "3. **Considerar modelos no lineales** (Decision Tree, Random Forest o XGBoost), que manejan mucho mejor estos casos.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 4. Gr√°fico de comparaci√≥n\n",
    "# ===================================\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.scatterplot(x=y_valid, y=preds, alpha=0.7)\n",
    "plt.plot([y_valid.min(), y_valid.max()],\n",
    "         [y_valid.min(), y_valid.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Predicciones vs Valores Reales - Regresi√≥n Lineal\")\n",
    "plt.xlabel(\"Valor real (Life Expectancy)\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## **Paso 5. Importancia de caracter√≠sticas (coeficientes del modelo)**\n",
    "\n",
    "üîé En este gr√°fico vemos la importancia relativa de cada variable en el modelo:  \n",
    "- Un **coeficiente positivo** implica que la variable est√° asociada con un aumento en la esperanza de vida.  \n",
    "- Un **coeficiente negativo** indica relaci√≥n inversa (a mayor valor de la variable, menor esperanza de vida).  \n",
    "- Esto nos da **interpretabilidad** del modelo, aunque hay que tener cuidado con la multicolinealidad (cuando varias variables est√°n muy correlacionadas entre s√≠).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 5. Importancia de variables (coeficientes)\n",
    "# ===================================\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Variable\": X_train.columns,\n",
    "    \"Coeficiente\": lr.coef_\n",
    "}).sort_values(by=\"Coeficiente\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.barplot(\n",
    "    x=\"Coeficiente\",\n",
    "    y=\"Variable\",\n",
    "    data=coef_df,\n",
    "    hue=\"Variable\",        # asignar la variable al hue\n",
    "    dodge=False,           # evita duplicados en barras\n",
    "    legend=False,          # no mostrar leyenda redundante\n",
    "    palette=\"coolwarm\"\n",
    ")\n",
    "plt.title(\"Coeficientes de la Regresi√≥n Lineal\", fontsize=14)\n",
    "plt.xlabel(\"Peso del coeficiente\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()\n",
    "\n",
    "# Mostrar top 10 coeficientes en tabla\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## **Paso 6. Diagn√≥stico de residuos en Regresi√≥n Lineal**\n",
    "\n",
    "\n",
    "Un **residuo** es la diferencia entre el valor real (`y_valid`) y la predicci√≥n del modelo (`preds`).  \n",
    "\n",
    "Analizar los residuos es importante porque:  \n",
    "- Si el modelo es adecuado, los residuos deber√≠an distribuirse alrededor de **0**, sin patrones claros.  \n",
    "- Residuos grandes indican observaciones mal ajustadas (posibles *outliers multivariados*).  \n",
    "- Si hay un patr√≥n sistem√°tico (curvas, abanicos, etc.), significa que la relaci√≥n **no es estrictamente lineal** y el modelo lineal no captura toda la complejidad.  \n",
    "\n",
    "En los gr√°ficos que veremos:  \n",
    "\n",
    "- **Gr√°fico real vs. predicciones**: si los puntos se agrupan alrededor de la diagonal (l√≠nea roja; l√≠nea `y = x`), el modelo se ajusta o est√° prediciendo bien. Si hay dispersi√≥n indica mala capacidad de predicci√≥n. \n",
    "\n",
    "- **Histograma / distribuci√≥n de residuos**: deber√≠a parecerse a una distribuci√≥n normal centrada en 0 (centrados en 0) y con forma aproximadamente normal. Colas largas sugieren outliers o mala especificaci√≥n.\n",
    "\n",
    "- **Gr√°fico de residuos vs. predicciones**: los residuos deber√≠an distribuirse o estar dispersos de manera aleatoria alrededor de 0 (sin curva o abanico). Si vemos un patr√≥n (curva, abanico, etc.), indica que el modelo lineal no est√° capturando bien la relaci√≥n.\n",
    "\n",
    "Estos gr√°ficos permiten detectar:  \n",
    "- **Heterocedasticidad**: cuando los residuos aumentan o disminuyen con el valor de las predicciones.  \n",
    "- **Outliers multivariados**: puntos con residuos extremadamente altos.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 6. Diagn√≥stico de residuos\n",
    "# ===================================\n",
    "\n",
    "# Calcular residuos\n",
    "residuos = y_valid - preds\n",
    "\n",
    "#--- Configuraci√≥n de estilo global ---\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (7,5),\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10\n",
    "})\n",
    "\n",
    "# --- Gr√°fico 1: Valores reales vs. predicciones ---\n",
    "plt.figure()\n",
    "sns.scatterplot(x=y_valid, y=preds, alpha=0.7, color=\"steelblue\", edgecolor=\"k\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], 'r--', linewidth=2)\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Valores reales vs. Predicciones\")\n",
    "plt.show()\n",
    "\n",
    "# --- Gr√°fico 2: Histograma de residuos ---\n",
    "plt.figure()\n",
    "sns.histplot(residuos, bins=30, kde=True, color=\"steelblue\")\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "plt.title(\"Distribuci√≥n de residuos\")\n",
    "plt.xlabel(\"Residuos (y_real - y_pred)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Gr√°fico 3: Residuos vs. Predicciones ---\n",
    "plt.figure()\n",
    "sns.scatterplot(x=preds, y=residuos, alpha=0.7, color=\"steelblue\", edgecolor=\"k\")\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "plt.xlabel(\"Predicciones\")\n",
    "plt.ylabel(\"Residuo\")\n",
    "plt.title(\"Residuos vs. Predicciones\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Chequeo estad√≠stico ---\n",
    "print(\"üìä Resumen de residuos:\")\n",
    "print(residuos.describe())\n",
    "\n",
    "# --- Detectar outliers multivariados ---\n",
    "umbral = 2 * residuos.std()  # criterio simple: 2 desviaciones est√°ndar\n",
    "outliers = residuos[np.abs(residuos) > umbral]\n",
    "print(f\"üîé Posibles outliers multivariados detectados: {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## **Paso 7. Conclusi√≥n del notebook del algoritmo de Regresi√≥n Lineal**\n",
    "\n",
    "# üìå Conclusiones de la Regresi√≥n Lineal\n",
    "- La regresi√≥n lineal ofrece una **primera aproximaci√≥n** sencilla para este problema.  \n",
    "- Funciona bien cuando la relaci√≥n entre variables es aproximadamente lineal y no hay demasiados outliers.  \n",
    "- Sus m√©tricas (RMSE, MAE, R¬≤) nos servir√°n de **baseline** para comparar con modelos m√°s avanzados como √Årboles de Decisi√≥n, Random Forest y XGBoost. \n",
    "\n",
    "\n",
    "- La **Regresi√≥n Lineal** se ha entrenado sobre el dataset ya procesado (outliers tratados, nulos imputados, variables codificadas y escaladas).  \n",
    "- Hemos obtenido m√©tricas de rendimiento razonables que servir√°n como **baseline**.  \n",
    "- Visualizamos las predicciones frente a los valores reales, comprobando la capacidad predictiva del modelo.  \n",
    "- Identificamos las variables m√°s influyentes mediante sus coeficientes.  \n",
    "- A partir de aqu√≠, podremos comparar este modelo con otros m√°s complejos (√°rboles, Random Forest, XGBoost, Ridge, Lasso, ElasticNet, KNN).  \n",
    "\n",
    "‚úÖ Este notebook queda como **referencia inicial** para nuestro proyecto.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
