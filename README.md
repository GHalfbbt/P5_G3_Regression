# ğŸ“Š P5_G3_Regression
Proyecto grupal de Machine Learning dentro del bootcamp de IA de [FactorÃ­a F5 â€“ Web Oficial](https://factoriaf5.org/)  
Nuestro objetivo es **predecir la esperanza de vida** a partir de indicadores socioeconÃ³micos y sanitarios, comparando distintos algoritmos de regresiÃ³n.


---

## ğŸš€ Objetivos
- Analizar el dataset de esperanza de vida mediante un **EDA riguroso**.
- Probar distintos algoritmos de regresiÃ³n (lineales y no lineales).
- Evaluar con mÃ©tricas de regresiÃ³n: **RMSE, MAE, RÂ²**.
- Comparar resultados entre compaÃ±eros y seleccionar el modelo con mejor rendimiento.


---

ğŸ‘¥ Autores

    
- [Umit Gungor](https://github.com/GungorUmit) â€” Data Analyst & Python Developer  
- [Johi Ortiz Vallejos](https://github.com/johiortiz) â€” Data Analyst & Python Developer  
- [Yeder Pimentel](https://github.com/Yedpt) â€” Data Analyst & Python Developer  
- [Alfonso BermÃºdez Torres](https://github.com/GHalfbbt) â€” Data Analyst & Python Developer

---

## ğŸ“‚ Estructura del repositorio
```bash
P5_G3_Regression/
â”‚â”€â”€ data/ # datasets (train/test)
â”‚â”€â”€ notebooks/ # notebooks de cada algoritmo evaluado
â”‚ â”œâ”€â”€ notebook_A.ipynb
â”‚ â”œâ”€â”€ notebook_B.ipynb
â”‚ â””â”€â”€ ...
â”‚â”€â”€ docs/ # documentos (PDF investigaciÃ³n, plan de trabajo, etc.)
â”œâ”€â”€ src/                      # scripts del pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocess.py         # limpieza + escalado + encoding
â”‚   â”œâ”€â”€ train_model.py        # entrenamiento modelos - crea *.pkl
â”‚   â”œâ”€â”€ predict.py            # cargar modelo y predecir
â”‚   â””â”€â”€ app.py                # PMV con Streamlit
â”‚
â”œâ”€â”€ models/                   # modelos guardados (son generados)
â”‚   â””â”€â”€ xgb_model.pkl
â”‚
â”‚â”€â”€ requirements.txt # dependencias del proyecto
â”‚â”€â”€ README.md # descripciÃ³n del proyecto
```

---

## ğŸ‘¥ OrganizaciÃ³n del trabajo
- Cada compaÃ±ero trabaja en su **algoritmo asignado** en un notebook propio.
- Los notebooks se suben en la carpeta `notebooks/`.
- Se evaluarÃ¡n los resultados de cada modelo segÃºn las mÃ©tricas acordadas.
- Finalmente se fusionarÃ¡ el mejor modelo en la rama `main` (o se dejarÃ¡n todos como referencia).

---

## ğŸ“Š Dataset
- **Fuente:** Life Expectancy Dataset (Kaggle / WHO).  
- **Variable objetivo:** Esperanza de vida (aÃ±os).  
- **CaracterÃ­sticas:** gasto en salud, mortalidad infantil, factores demogrÃ¡ficos, socioeconÃ³micos, etc.

ğŸ”— [Dataset Life Expectancy Kaggle](https://www.kaggle.com/code/wrecked22/life-expectancy-regression)

---

## ğŸ› ï¸ TecnologÃ­as
- Python, Jupyter Lab
- Numpy, Pandas, Scikit-learn
- Matplotlib, Seaborn
- GitHub para control de versiones y organizaciÃ³n

---

## âš™ï¸ InstalaciÃ³n y entorno de ejecuciÃ³n

### ğŸ”§ Requisitos previos
- Python 3.9+  
- git instalado  

### ğŸ’» Clonar repositorio
```bash
git clone https://github.com/usuario/P5_G3_Regression.git
cd P5_G3_Regression
```


ğŸ–¥ï¸ Crear entorno virtual
Windows (PowerShell)

```bash
python -m venv venv
venv\Scripts\activate
```


Linux / Mac
```bash
python3 -m venv venv
source venv/bin/activate
```

ğŸ“¦ Instalar dependencias
Este proyecto incluye un archivo requirements.txt con las librerÃ­as necesarias.
Ejecuta el siguiente comando dentro del entorno virtual:
```bash
pip install -r requirements.txt
```
Contenido sugerido de requirements.txt:
numpy
pandas
scikit-learn
matplotlib
seaborn
jupyterlab
xgboost
lightgbm
optuna

â–¶ï¸ Ejecutar Jupyter Lab
```bash
jupyter lab
```


---

## âœ… Tareas principales
1. InvestigaciÃ³n y entrega en PDF.
2. SelecciÃ³n y anÃ¡lisis del dataset.
3. Exploratory Data Analysis (EDA).
4. ImplementaciÃ³n de modelos baseline.
5. ImplementaciÃ³n de algoritmos avanzados (Random Forest, XGBoost, etc.).
6. ComparaciÃ³n de resultados y elecciÃ³n del mejor modelo.
7. DocumentaciÃ³n y entrega final.

---

## ğŸ”„ Flujo de trabajo con Git
- `main`: rama estable con el proyecto consolidado.
- `feature/algoritmo_nombre`: ramas donde cada compaÃ±ero desarrolla su notebook.  
- Pull requests para fusionar a `main`.

---

## ğŸ“Œ Notas
Este proyecto **no es una competiciÃ³n oficial de Kaggle**, pero se inspira en su dinÃ¡mica.  
Cada miembro probarÃ¡ un algoritmo distinto y evaluaremos cuÃ¡l se comporta mejor con las mÃ©tricas seleccionadas.
